# Docker Compose con Celery - Backend V2

Gu칤a para ejecutar Backend V2 con Celery usando Docker Compose.

## 游 Quick Start

```bash
# 1. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# 2. Levantar todos los servicios
docker-compose up -d

# 3. Ver logs
docker-compose logs -f celery-worker
docker-compose logs -f celery-beat
```

## 游닍 Servicios Incluidos

### 1. **backend** - FastAPI (puerto 8000)
Servidor web principal con endpoints REST.

```bash
# Ver logs
docker-compose logs -f backend

# Reiniciar
docker-compose restart backend
```

### 2. **celery-worker** - Worker de Celery
Procesa tareas SII en background (scraping, sincronizaci칩n).

```bash
# Ver logs
docker-compose logs -f celery-worker

# Escalar workers (m치s capacidad)
docker-compose up -d --scale celery-worker=3

# Reiniciar
docker-compose restart celery-worker
```

### 3. **celery-beat** - Scheduler
Programa tareas peri칩dicas (syncs autom치ticos).

```bash
# Ver logs
docker-compose logs -f celery-beat

# Reiniciar
docker-compose restart celery-beat
```

### 4. **redis** - Message Broker (puerto 6379)
Cola de mensajes para Celery.

```bash
# Ver logs
docker-compose logs -f redis

# Conectarse a Redis CLI
docker-compose exec redis redis-cli

# Ver tareas en cola
docker-compose exec redis redis-cli LLEN celery
```

### 5. **ngrok** - Tunnel p칰blico (puerto 4040)
Para webhooks en desarrollo.

```bash
# Ver URL p칰blica
open http://localhost:4040
```

## 丘뙖잺 Variables de Entorno Requeridas

### Para FastAPI y Worker

```bash
# Supabase (requerido)
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_SERVICE_KEY=eyJ...
SUPABASE_ANON_KEY=eyJ...

# OpenAI (para agentes)
OPENAI_API_KEY=sk-...

# Redis (auto-configurado en Docker)
REDIS_URL=redis://redis:6379/0
```

### Solo para Beat Scheduler

```bash
# PostgreSQL dedicado para Beat scheduler
# IMPORTANTE: Usar una DB dedicada en Railway (NO Supabase)
# Railway provee PostgreSQL gratis para proyectos peque침os
DATABASE_URL=postgresql://user:pass@containers-us-west-xxx.railway.app:5432/railway

# Notas:
# - DATABASE_URL es SOLO para el Beat scheduler (sqlalchemy-celery-beat)
# - Las tareas usan Supabase client (SUPABASE_URL), NO DATABASE_URL
# - Usar DB dedicada evita conflictos con tablas de aplicaci칩n
# - Railway auto-gestiona backups y escalamiento
```

## 游댢 Comandos 칔tiles

### Iniciar/Detener Servicios

```bash
# Levantar todos los servicios
docker-compose up -d

# Levantar servicios espec칤ficos
docker-compose up -d backend celery-worker

# Detener todo
docker-compose down

# Detener y eliminar vol칰menes (limpia Redis data)
docker-compose down -v
```

### Logs y Debugging

```bash
# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs de un servicio espec칤fico
docker-compose logs -f celery-worker

# Ver 칰ltimas 100 l칤neas
docker-compose logs --tail=100 celery-worker

# Ver logs con timestamps
docker-compose logs -f --timestamps celery-worker
```

### Ejecutar Comandos

```bash
# Shell interactivo en worker
docker-compose exec celery-worker bash

# Ejecutar tarea manualmente
docker-compose exec celery-worker python -c "
from app.infrastructure.celery.tasks.sii import sync_documents
result = sync_documents.delay('company-id', months=1)
print(f'Task ID: {result.id}')
"

# Ver Python packages instalados
docker-compose exec celery-worker pip list

# Ejecutar tests
docker-compose exec backend pytest tests/ -v
```

### Monitoring

```bash
# Ver estado de Redis
docker-compose exec redis redis-cli INFO

# Ver tareas pendientes en cola 'low'
docker-compose exec redis redis-cli LLEN low

# Ver tareas pendientes en cola 'default'
docker-compose exec redis redis-cli LLEN default

# Vaciar todas las colas (limpiar tareas pendientes)
docker-compose exec redis redis-cli FLUSHALL
```

### Rebuild y Update

```bash
# Rebuild im치genes (despu칠s de cambiar pyproject.toml)
docker-compose build

# Rebuild sin cache (forzar reinstalaci칩n completa)
docker-compose build --no-cache

# Rebuild y reiniciar
docker-compose up -d --build
```

## 游늵 Configuraci칩n de Workers

### Escalar Workers

Para manejar m치s carga, puedes escalar los workers:

```bash
# Escalar a 3 workers
docker-compose up -d --scale celery-worker=3

# Verificar
docker-compose ps
```

### Configurar Concurrency

En `docker-compose.yml` o via variables de entorno:

```yaml
celery-worker:
  environment:
    - CELERY_CONCURRENCY=4  # 4 tareas simult치neas por worker
    - CELERY_LOG_LEVEL=debug  # M치s detalle en logs
```

O al iniciar:

```bash
CELERY_CONCURRENCY=4 docker-compose up -d celery-worker
```

## 游냍 Troubleshooting

### Worker no procesa tareas

```bash
# 1. Verificar que Redis est치 funcionando
docker-compose exec redis redis-cli ping
# Debe retornar: PONG

# 2. Ver logs del worker
docker-compose logs -f celery-worker

# 3. Verificar que las tareas est치n en cola
docker-compose exec redis redis-cli LLEN low
docker-compose exec redis redis-cli LLEN default

# 4. Reiniciar worker
docker-compose restart celery-worker
```

### Beat no programa tareas

```bash
# 1. Verificar DATABASE_URL configurado
docker-compose exec celery-beat env | grep DATABASE_URL

# 2. Ver logs de Beat
docker-compose logs -f celery-beat

# 3. Verificar conexi칩n a PostgreSQL
docker-compose exec celery-beat bash -c \
  'psql $DATABASE_URL -c "SELECT * FROM celery_schema.celery_periodictask LIMIT 5;"'

# 4. Reiniciar Beat
docker-compose restart celery-beat
```

### Redis connection refused

```bash
# 1. Verificar que Redis est치 corriendo
docker-compose ps redis

# 2. Ver logs de Redis
docker-compose logs redis

# 3. Reiniciar Redis
docker-compose restart redis

# 4. Si sigue fallando, recrear container
docker-compose rm -f redis
docker-compose up -d redis
```

### Worker crashes con OOM (Out of Memory)

```bash
# Reducir concurrency en docker-compose.yml
environment:
  - CELERY_CONCURRENCY=1  # Menos tareas simult치neas

# O aumentar memoria del container
deploy:
  resources:
    limits:
      memory: 2G  # Aumentar a 2GB
```

### Tareas muy lentas

```bash
# Ver tareas activas
docker-compose exec redis redis-cli LLEN celery

# Ver tareas que est치n ejecut치ndose ahora
docker-compose logs --tail=50 celery-worker | grep "Task"

# Aumentar timeout
environment:
  - CELERY_TASK_TIME_LIMIT=3600  # 1 hora
```

## 游늳 Producci칩n

### Recomendaciones

1. **Usar servicios externos** (no containers):
   - **PostgreSQL (Beat)**: Railway PostgreSQL (dedicado para scheduler)
   - **Redis**: Upstash Redis (gratis hasta 10K comandos/d칤a)
   - **Supabase**: Para datos de aplicaci칩n (separado de Beat)

2. **Variables de entorno** en `.env`:
   ```bash
   # PostgreSQL dedicado para Beat (Railway)
   DATABASE_URL=postgresql://user:pass@containers-us-west-xxx.railway.app:5432/railway

   # Redis externo (Upstash)
   REDIS_URL=redis://:password@us1-xxx.upstash.io:6379

   # Supabase (datos de aplicaci칩n)
   SUPABASE_URL=https://xxx.supabase.co
   SUPABASE_SERVICE_KEY=eyJ...
   ```

   **쯇or qu칠 DB dedicada para Beat?**
   - Aislamiento: Evita conflictos con tablas de aplicaci칩n
   - Simplicidad: No necesita RLS ni pol칤ticas de Supabase
   - Railway: Provee PostgreSQL gratis con backups autom치ticos
   - Escalamiento: F치cil migrar a DB m치s grande si crece

3. **Escalar workers** seg칰n carga:
   ```bash
   docker-compose up -d --scale celery-worker=5
   ```

4. **Monitoring** con Flower:
   ```yaml
   flower:
     image: mher/flower
     command: celery --broker=$REDIS_URL flower --port=5555
     ports:
       - "5555:5555"
     environment:
       - CELERY_BROKER_URL=$REDIS_URL
   ```

5. **Logs centralizados**:
   - CloudWatch, Datadog, o Sentry
   - Capturar stderr/stdout de containers

### Deployment

Para producci칩n, considera usar orquestadores:

- **Railway**: Deploy directo desde GitHub
- **Render**: Deploy de containers con auto-scaling
- **AWS ECS/Fargate**: Escalamiento empresarial
- **Kubernetes**: Para control total

## 游댕 Referencias

- [docker-compose.yml](docker-compose.yml) - Configuraci칩n de servicios
- [Dockerfile](Dockerfile) - Imagen de containers
- [docker-entrypoint.sh](docker-entrypoint.sh) - Entry point
- [Celery README](app/infrastructure/celery/README.md) - Documentaci칩n de tareas
